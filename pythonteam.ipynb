{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4587721d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting torch\n",
      "  Using cached torch-1.11.0-cp39-cp39-win_amd64.whl (157.9 MB)\n",
      "Requirement already satisfied: typing-extensions in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (4.1.1)\n",
      "Installing collected packages: torch\n",
      "Successfully installed torch-1.11.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The scripts convert-caffe2-to-onnx.exe, convert-onnx-to-caffe2.exe and torchrun.exe are installed in 'C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d61e2ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting gluonnlp\n",
      "  Using cached gluonnlp-0.10.0.tar.gz (344 kB)\n",
      "Requirement already satisfied: numpy>=1.16.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from gluonnlp) (1.21.5)\n",
      "Requirement already satisfied: cython in c:\\programdata\\anaconda3\\lib\\site-packages (from gluonnlp) (0.29.28)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from gluonnlp) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from packaging->gluonnlp) (3.0.4)\n",
      "Building wheels for collected packages: gluonnlp\n",
      "  Building wheel for gluonnlp (setup.py): started\n",
      "  Building wheel for gluonnlp (setup.py): finished with status 'done'\n",
      "  Created wheel for gluonnlp: filename=gluonnlp-0.10.0-cp39-cp39-win_amd64.whl size=454507 sha256=b55fff0f7f94502ecf3719112e27584e804f660601aa715a53e34be265fb6d81\n",
      "  Stored in directory: c:\\users\\admin\\appdata\\local\\pip\\cache\\wheels\\47\\17\\70\\b257bc53879a458c4bfcc900e89271aa8b4f19366a54bd2455\n",
      "Successfully built gluonnlp\n",
      "Installing collected packages: gluonnlp\n",
      "Successfully installed gluonnlp-0.10.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gluonnlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c425add",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting mxnet\n",
      "  Using cached mxnet-1.7.0.post2-py2.py3-none-win_amd64.whl (33.1 MB)\n",
      "Collecting requests<2.19.0,>=2.18.4\n",
      "  Using cached requests-2.18.4-py2.py3-none-any.whl (88 kB)\n",
      "Collecting numpy<1.17.0,>=1.8.2\n",
      "  Using cached numpy-1.16.6.zip (5.1 MB)\n",
      "Collecting graphviz<0.9.0,>=0.8.1\n",
      "  Using cached graphviz-0.8.4-py2.py3-none-any.whl (16 kB)\n",
      "Collecting urllib3<1.23,>=1.21.1\n",
      "  Using cached urllib3-1.22-py2.py3-none-any.whl (132 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<2.19.0,>=2.18.4->mxnet) (2021.10.8)\n",
      "Collecting idna<2.7,>=2.5\n",
      "  Using cached idna-2.6-py2.py3-none-any.whl (56 kB)\n",
      "Collecting chardet<3.1.0,>=3.0.2\n",
      "  Using cached chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
      "Building wheels for collected packages: numpy\n",
      "  Building wheel for numpy (setup.py): started\n",
      "  Building wheel for numpy (setup.py): still running...\n",
      "  Building wheel for numpy (setup.py): still running...\n",
      "  Building wheel for numpy (setup.py): finished with status 'done'\n",
      "  Created wheel for numpy: filename=numpy-1.16.6-cp39-cp39-win_amd64.whl size=3712734 sha256=6f80b0065e9b95bba0aace61da51562075cb687bba39b05a797e47ce3d875507\n",
      "  Stored in directory: c:\\users\\admin\\appdata\\local\\pip\\cache\\wheels\\ce\\72\\38\\377a1055ac9b575ebba22e507856aecdc37f9bf6372703e5f9\n",
      "Successfully built numpy\n",
      "Installing collected packages: urllib3, idna, chardet, requests, numpy, graphviz, mxnet\n",
      "Successfully installed chardet-3.0.4 graphviz-0.8.4 idna-2.6 mxnet-1.7.0.post2 numpy-1.16.6 requests-2.18.4 urllib3-1.22\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script chardetect.exe is installed in 'C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script f2py.exe is installed in 'C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "spyder 5.1.5 requires pyqt5<5.13, which is not installed.\n",
      "spyder 5.1.5 requires pyqtwebengine<5.13, which is not installed.\n",
      "daal4py 2021.5.0 requires daal==2021.4.0, which is not installed.\n",
      "conda-repo-cli 1.0.4 requires pathlib, which is not installed.\n",
      "anaconda-project 0.10.2 requires ruamel-yaml, which is not installed.\n",
      "selenium 4.2.0 requires urllib3[secure,socks]~=1.26, but you have urllib3 1.22 which is incompatible.\n",
      "xarray 0.20.1 requires numpy>=1.18, but you have numpy 1.16.6 which is incompatible.\n",
      "statsmodels 0.13.2 requires numpy>=1.17, but you have numpy 1.16.6 which is incompatible.\n",
      "scikit-image 0.19.2 requires numpy>=1.17.0, but you have numpy 1.16.6 which is incompatible.\n",
      "pywavelets 1.3.0 requires numpy>=1.17.3, but you have numpy 1.16.6 which is incompatible.\n",
      "pyerfa 2.0.0 requires numpy>=1.17, but you have numpy 1.16.6 which is incompatible.\n",
      "pandas 1.4.2 requires numpy>=1.18.5; platform_machine != \"aarch64\" and platform_machine != \"arm64\" and python_version < \"3.10\", but you have numpy 1.16.6 which is incompatible.\n",
      "numba 0.55.1 requires numpy<1.22,>=1.18, but you have numpy 1.16.6 which is incompatible.\n",
      "matplotlib 3.5.1 requires numpy>=1.17, but you have numpy 1.16.6 which is incompatible.\n",
      "gensim 4.1.2 requires numpy>=1.17.0, but you have numpy 1.16.6 which is incompatible.\n",
      "cookiecutter 1.7.3 requires requests>=2.23.0, but you have requests 2.18.4 which is incompatible.\n",
      "botocore 1.24.32 requires urllib3<1.27,>=1.25.4, but you have urllib3 1.22 which is incompatible.\n",
      "astropy 5.0.4 requires numpy>=1.18, but you have numpy 1.16.6 which is incompatible.\n",
      "anyio 3.5.0 requires idna>=2.8, but you have idna 2.6 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "pip install mxnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ad6ffaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: ipywidgets in c:\\programdata\\anaconda3\\lib\\site-packages (7.6.5)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from ipywidgets) (6.9.1)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from ipywidgets) (5.3.0)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from ipywidgets) (1.0.0)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from ipywidgets) (3.5.2)\n",
      "Requirement already satisfied: ipython>=4.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from ipywidgets) (8.2.0)\n",
      "Requirement already satisfied: tornado<7.0,>=4.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (6.1)\n",
      "Requirement already satisfied: debugpy<2.0,>=1.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (1.5.1)\n",
      "Requirement already satisfied: matplotlib-inline<0.2.0,>=0.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.2)\n",
      "Requirement already satisfied: jupyter-client<8.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (6.1.12)\n",
      "Requirement already satisfied: nest-asyncio in c:\\programdata\\anaconda3\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (1.5.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (3.0.20)\n",
      "Requirement already satisfied: setuptools>=18.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (61.2.0)\n",
      "Requirement already satisfied: backcall in c:\\programdata\\anaconda3\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\programdata\\anaconda3\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (0.18.1)\n",
      "Requirement already satisfied: stack-data in c:\\programdata\\anaconda3\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (2.11.2)\n",
      "Requirement already satisfied: decorator in c:\\programdata\\anaconda3\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (0.4.4)\n",
      "Requirement already satisfied: pickleshare in c:\\programdata\\anaconda3\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (0.7.5)Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: jupyter-core>=4.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (4.9.2)\n",
      "Requirement already satisfied: pyzmq>=13 in c:\\programdata\\anaconda3\\lib\\site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (22.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (2.8.2)\n",
      "Requirement already satisfied: pywin32>=1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jupyter-core>=4.6.0->jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (302)\n",
      "Requirement already satisfied: jsonschema>=2.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from nbformat>=4.2.0->ipywidgets) (4.4.0)\n",
      "Requirement already satisfied: fastjsonschema in c:\\programdata\\anaconda3\\lib\\site-packages (from nbformat>=4.2.0->ipywidgets) (2.15.1)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets) (0.18.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets) (21.4.0)\n",
      "Requirement already satisfied: wcwidth in c:\\programdata\\anaconda3\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.1->jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (1.16.0)\n",
      "Requirement already satisfied: notebook>=4.4.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from widgetsnbextension~=3.5.0->ipywidgets) (6.4.8)\n",
      "Requirement already satisfied: argon2-cffi in c:\\programdata\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (21.3.0)\n",
      "Requirement already satisfied: Send2Trash>=1.8.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.8.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.13.1)\n",
      "Requirement already satisfied: prometheus-client in c:\\programdata\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.13.1)\n",
      "\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.11.3)\n",
      "Requirement already satisfied: nbconvert in c:\\programdata\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (6.4.4)\n",
      "Requirement already satisfied: pywinpty>=1.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from terminado>=0.8.3->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.0.2)\n",
      "Requirement already satisfied: argon2-cffi-bindings in c:\\programdata\\anaconda3\\lib\\site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (21.2.0)\n",
      "Requirement already satisfied: cffi>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.15.0)\n",
      "Requirement already satisfied: pycparser in c:\\programdata\\anaconda3\\lib\\site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.21)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.0.1)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.4)\n",
      "Requirement already satisfied: defusedxml in c:\\programdata\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.7.1)\n",
      "Requirement already satisfied: bleach in c:\\programdata\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (4.1.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\programdata\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (4.11.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in c:\\programdata\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.1.2)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.5.0)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.13)\n",
      "Requirement already satisfied: testpath in c:\\programdata\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from beautifulsoup4->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.3.1)\n",
      "Requirement already satisfied: webencodings in c:\\programdata\\anaconda3\\lib\\site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.1)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from packaging->bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (3.0.4)\n",
      "Requirement already satisfied: executing in c:\\programdata\\anaconda3\\lib\\site-packages (from stack-data->ipython>=4.0.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: asttokens in c:\\programdata\\anaconda3\\lib\\site-packages (from stack-data->ipython>=4.0.0->ipywidgets) (2.0.5)\n",
      "Requirement already satisfied: pure-eval in c:\\programdata\\anaconda3\\lib\\site-packages (from stack-data->ipython>=4.0.0->ipywidgets) (0.2.2)\n"
     ]
    }
   ],
   "source": [
    "pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c1c6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install git+https://git@github.com/SKTBrain/KoBERT.git@master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a682feb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802130e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1774bbe6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43498d3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3bfe6157",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'kobert'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 10>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnotebook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkobert\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_tokenizer\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkobert\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_pytorch_kobert_model\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AdamW\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'kobert'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import gluonnlp as nlp\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from kobert import get_tokenizer\n",
    "from kobert import get_pytorch_kobert_model\n",
    "\n",
    "from transformers import AdamW\n",
    "from transformers.optimization import get_cosine_schedule_with_warmup\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "bertmodel, vocab = get_pytorch_kobert_model(cachedir=\".cache\")\n",
    "\n",
    "\n",
    "dataset_train = nlp.data.TSVDataset(\".cache/ratings_train.txt\", field_indices=[1,2], num_discard_samples=1)\n",
    "dataset_test = nlp.data.TSVDataset(\".cache/ratings_test.txt\", field_indices=[1,2], num_discard_samples=1)\n",
    "\n",
    "tokenizer = get_tokenizer()\n",
    "tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)\n",
    "\n",
    "class BERTDataset(Dataset):\n",
    "    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, max_len,\n",
    "                 pad, pair):\n",
    "        transform = nlp.data.BERTSentenceTransform(\n",
    "            bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair)\n",
    "\n",
    "        self.sentences = [transform([i[sent_idx]]) for i in dataset]\n",
    "        self.labels = [np.int32(i[label_idx]) for i in dataset]\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return (self.sentences[i] + (self.labels[i], ))\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.labels))\n",
    "\n",
    "## Setting parameters\n",
    "max_len = 64\n",
    "batch_size = 64\n",
    "warmup_ratio = 0.1\n",
    "num_epochs = 5\n",
    "max_grad_norm = 1\n",
    "log_interval = 200\n",
    "learning_rate =  5e-5\n",
    "\n",
    "data_train = BERTDataset(dataset_train, 0, 1, tok, max_len, True, False)\n",
    "data_test = BERTDataset(dataset_test, 0, 1, tok, max_len, True, False)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(data_train, batch_size=batch_size, num_workers=5)\n",
    "test_dataloader = torch.utils.data.DataLoader(data_test, batch_size=batch_size, num_workers=5)\n",
    "\n",
    "class BERTClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "                 bert,\n",
    "                 hidden_size = 768,\n",
    "                 num_classes=2,\n",
    "                 dr_rate=None,\n",
    "                 params=None):\n",
    "        super(BERTClassifier, self).__init__()\n",
    "        self.bert = bert\n",
    "        self.dr_rate = dr_rate\n",
    "                 \n",
    "        self.classifier = nn.Linear(hidden_size , num_classes)\n",
    "        if dr_rate:\n",
    "            self.dropout = nn.Dropout(p=dr_rate)\n",
    "    \n",
    "    def gen_attention_mask(self, token_ids, valid_length):\n",
    "        attention_mask = torch.zeros_like(token_ids)\n",
    "        for i, v in enumerate(valid_length):\n",
    "            attention_mask[i][:v] = 1\n",
    "        return attention_mask.float()\n",
    "\n",
    "    def forward(self, token_ids, valid_length, segment_ids):\n",
    "        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
    "        \n",
    "        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n",
    "        if self.dr_rate:\n",
    "            out = self.dropout(pooler)\n",
    "        else:\n",
    "            out = pooler\n",
    "        return self.classifier(out)\n",
    "\n",
    "model = BERTClassifier(bertmodel,  dr_rate=0.5).to(device)\n",
    "\n",
    "# Prepare optimizer and schedule (linear warmup and decay)\n",
    "no_decay = ['bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "]\n",
    "\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "t_total = len(train_dataloader) * num_epochs\n",
    "warmup_step = int(t_total * warmup_ratio)\n",
    "\n",
    "scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=warmup_step, num_training_steps=t_total)\n",
    "\n",
    "def calc_accuracy(X,Y):\n",
    "    max_vals, max_indices = torch.max(X, 1)\n",
    "    train_acc = (max_indices == Y).sum().data.cpu().numpy()/max_indices.size()[0]\n",
    "    return train_acc\n",
    "\n",
    "PATH = \"/content/News.pt\"\n",
    "\n",
    "# 불러오기\n",
    "device = torch.device(\"cuda\")\n",
    "model = BERTClassifier(bertmodel,  dr_rate=0.5).to(device)\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# 위에서 설정한 tok, max_len, batch_size, device를 그대로 입력\n",
    "# comment : 예측하고자 하는 텍스트 데이터 리스트\n",
    "def getSentimentValue(comment, tok, max_len, batch_size, device):\n",
    "  commnetslist = [] # 텍스트 데이터를 담을 리스트\n",
    "  emo_list = [] # 감성 값을 담을 리스트\n",
    "  # for c in comment: # 모든 댓글\n",
    "  commnetslist.append( [comment, 5] ) # [댓글, 임의의 양의 정수값] 설정\n",
    "    \n",
    "  pdData = pd.DataFrame( commnetslist, columns = [['댓글', '감성']] )\n",
    "  pdData = pdData.values\n",
    "  test_set = BERTDataset(pdData, 0, 1, tok, max_len, True, False) \n",
    "  test_input = torch.utils.data.DataLoader(test_set, batch_size=batch_size, num_workers=5)\n",
    "  \n",
    "  for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(test_input):\n",
    "    token_ids = token_ids.long().to(device)\n",
    "    segment_ids = segment_ids.long().to(device)\n",
    "    valid_length= valid_length \n",
    "    # 이때, out이 예측 결과 리스트\n",
    "    out = model(token_ids, valid_length, segment_ids)\n",
    "\t\n",
    "    # e는 2가지 실수 값으로 구성된 리스트\n",
    "    # 0번 인덱스가 더 크면 부정, 긍정은 반대\n",
    "    for e in out:\n",
    "      if e[0]>e[1]: # 부정\n",
    "        value = 0\n",
    "      else: #긍정\n",
    "        value = 1\n",
    "      emo_list.append(value)\n",
    "\n",
    "  return emo_list # 텍스트 데이터에 1대1 매칭되는 감성값 리스트 반환\n",
    "\n",
    "from numpy import genfromtxt\n",
    "import numpy as np\n",
    "\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen, re\n",
    "\n",
    "########### 전일 거래량 20종목 가져오기 ############\n",
    "\n",
    "def getStocks():    \n",
    "    # 주식수 (20개)\n",
    "    stockNum = 20\n",
    "\n",
    "    # 해당 페이지가 주식 정보를 동적으로 만들어 selenium으로 데이터를 가져온다.\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument('headless')\n",
    "\n",
    "    driver = webdriver.Chrome('chromedriver.exe', options=options)\n",
    "\n",
    "\n",
    "    ####################### 종목명, 종목정보 링크(etf종목 구별할 때 사용) #################\n",
    "\n",
    "    driver.get('https://finance.naver.com/sise/sise_quant.naver')\n",
    "\n",
    "    time.sleep(5)\n",
    "    bs = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "    # 테이블에서 PER|ROE|영업이익(etf,etn면 N/A) 위치\n",
    "    index = 0 \n",
    "    ths = bs.find(class_='type_2').find('tbody').find('tr').find_all('th')\n",
    "    for i in range(len(ths)):\n",
    "        if(ths[i].get_text() == 'PER' or ths[i].get_text() == 'ROE' or ths[i].get_text() == '영업이익'):\n",
    "            index = i+1\n",
    "            break\n",
    "            \n",
    "    \n",
    "    # 테이블의 종목당 정보들 \n",
    "    stocks = bs.find(class_='type_2').find('tbody').find_all('tr')\n",
    "\n",
    "    result = []\n",
    "\n",
    "    count = 0\n",
    "    # count가 주식 수를 채울 때 까지 반복\n",
    "    for i in range(len(stocks)):\n",
    "        \n",
    "        # 테이블에서 종목당 종목 정보만 가져오기\n",
    "        stock = None\n",
    "        try:\n",
    "            no = stocks[i].find(class_=\"no\").get_text()\n",
    "            stock=stocks[i]\n",
    "        except AttributeError:\n",
    "            continue\n",
    "        \n",
    "        # PER|ROE|영업이익 N/A가 아니면 종목명 리스트에 넣기\n",
    "        if(stock.select('td:nth-child({})'.format(index))[0].get_text() != 'N/A'):\n",
    "            result.append(stock.find(class_=\"tltle\").get_text()) \n",
    "            count += 1\n",
    "        \n",
    "        # 원하는 종목 만큼 (stockNum == 20)\n",
    "        if(count>=stockNum):\n",
    "            break\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "    return result\n",
    "\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen, re\n",
    "\n",
    "########### 전일 거래량 20종목 가져오기 ############\n",
    "\n",
    "def getStocks():    \n",
    "    # 주식수 (20개)\n",
    "    stockNum = 20\n",
    "\n",
    "    # 해당 페이지가 주식 정보를 동적으로 만들어 selenium으로 데이터를 가져온다.\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument('headless')\n",
    "\n",
    "    driver = webdriver.Chrome('chromedriver.exe', options=options)\n",
    "\n",
    "\n",
    "    ####################### 종목명, 종목정보 링크(etf종목 구별할 때 사용) #################\n",
    "\n",
    "    driver.get('https://finance.naver.com/sise/sise_quant.naver')\n",
    "\n",
    "    time.sleep(5)\n",
    "    bs = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "    # 테이블에서 PER|ROE|영업이익(etf,etn면 N/A) 위치\n",
    "    index = 0 \n",
    "    ths = bs.find(class_='type_2').find('tbody').find('tr').find_all('th')\n",
    "    for i in range(len(ths)):\n",
    "        if(ths[i].get_text() == 'PER' or ths[i].get_text() == 'ROE' or ths[i].get_text() == '영업이익'):\n",
    "            index = i+1\n",
    "            break\n",
    "            \n",
    "    \n",
    "    # 테이블의 종목당 정보들 \n",
    "    stocks = bs.find(class_='type_2').find('tbody').find_all('tr')\n",
    "\n",
    "    result = []\n",
    "\n",
    "    count = 0\n",
    "    # count가 주식 수를 채울 때 까지 반복\n",
    "    for i in range(len(stocks)):\n",
    "        \n",
    "        # 테이블에서 종목당 종목 정보만 가져오기\n",
    "        stock = None\n",
    "        try:\n",
    "            no = stocks[i].find(class_=\"no\").get_text()\n",
    "            stock=stocks[i]\n",
    "        except AttributeError:\n",
    "            continue\n",
    "        \n",
    "        # PER|ROE|영업이익 N/A가 아니면 종목명 리스트에 넣기\n",
    "        if(stock.select('td:nth-child({})'.format(index))[0].get_text() != 'N/A'):\n",
    "            result.append(stock.find(class_=\"tltle\").get_text()) \n",
    "            count += 1\n",
    "        \n",
    "        # 원하는 종목 만큼 (stockNum == 20)\n",
    "        if(count>=stockNum):\n",
    "            break\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "    return result\n",
    "\n",
    "#주식 거래량 상위 20위 \n",
    "stocksList = getStocks()\n",
    "\n",
    "#뉴스 헤드라인 크롤링 > 엑셀파일로 저장 \n",
    "start(stocksList)\n",
    "\n",
    "\n",
    "import csv\n",
    "\n",
    "file = open('test1.csv', encoding='cp949')\n",
    "\n",
    "type(file)\n",
    "\n",
    "csvreader = csv.reader(file)\n",
    "\n",
    "rows = []\n",
    "names = []\n",
    "for row in csvreader:\n",
    "  if row[0] != '종목이름' and row[1]!= '기사제목':\n",
    "    names.append(row[0])\n",
    "    rows.append(row[1])\n",
    "rows\n",
    "\n",
    "\n",
    "\n",
    "for s in rows:\n",
    "  # if len(s)>0 and s !='삼성전자':\n",
    "  #   s=str(s)\n",
    "  print(getSentimentValue(s, tok, max_len, batch_size, device),s)\n",
    "\n",
    "count=0\n",
    "\n",
    "for s in rows:\n",
    "  if getSentimentValue(s, tok, max_len, batch_size, device)[0] == 1:\n",
    "    count = count + 1\n",
    "\n",
    "print(count)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0abe59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
